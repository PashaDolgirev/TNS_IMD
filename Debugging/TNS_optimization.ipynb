{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56796ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as sp\n",
    "import scipy.integrate as spi\n",
    "\n",
    "from scipy.optimize import brentq, fsolve\n",
    "from scipy.integrate import quad\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensornetwork as tn\n",
    "\n",
    "# Set TensorNetwork to use the TensorFlow backend (needed for autodiff)\n",
    "# tn.set_default_backend(\"tensorflow\")\n",
    "tn.set_default_backend(\"jax\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceb7aa15",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Shapes must be 1D sequences of concrete values of integer type, got [2, 1.0].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     prod_tensors\u001b[38;5;241m.\u001b[39mappend(v\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# Convert to numpy array\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize FiniteMPS (in canonical form)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m psi_initial \u001b[38;5;241m=\u001b[39m tn\u001b[38;5;241m.\u001b[39mFiniteMPS(prod_tensors, canonicalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Step 1: Define the Hadamard gate (in real numbers)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m Hgate \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m], [\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2.0\u001b[39m), tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensornetwork/matrixproductstates/finite_mps.py:84\u001b[0m, in \u001b[0;36mFiniteMPS.__init__\u001b[0;34m(self, tensors, center_position, canonicalize, backend)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 84\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     85\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition(center_position)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensornetwork/matrixproductstates/base_mps.py:182\u001b[0m, in \u001b[0;36mBaseMPS.position\u001b[0;34m(self, site, normalize, D, max_truncation_err)\u001b[0m\n\u001b[1;32m    179\u001b[0m use_svd \u001b[38;5;241m=\u001b[39m (D \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m D \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbond_dimension(n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    180\u001b[0m           ) \u001b[38;5;129;01mor\u001b[39;00m max_truncation_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_svd:\n\u001b[0;32m--> 182\u001b[0m   isometry, rest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors[n])\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m   isometry, S, V, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors[n], \u001b[38;5;241m2\u001b[39m, D,\n\u001b[1;32m    185\u001b[0m                                max_truncation_err)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensornetwork/backends/decorators.py:74\u001b[0m, in \u001b[0;36mjit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     72\u001b[0m   jitted \u001b[38;5;241m=\u001b[39m backend_obj\u001b[38;5;241m.\u001b[39mjit(fun, static_argnums\u001b[38;5;241m=\u001b[39mstatic_argnums,\n\u001b[1;32m     73\u001b[0m                            device\u001b[38;5;241m=\u001b[39mdevice, backend\u001b[38;5;241m=\u001b[39mxla_backend)\n\u001b[0;32m---> 74\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jitted(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensornetwork/matrixproductstates/base_mps.py:113\u001b[0m, in \u001b[0;36mBaseMPS.__init__.<locals>.qr\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@partial\u001b[39m(jit, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqr\u001b[39m(tensor):\n\u001b[0;32m--> 113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mqr(tensor, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensornetwork/backends/jax/jax_backend.py:95\u001b[0m, in \u001b[0;36mJaxBackend.qr\u001b[0;34m(self, tensor, pivot_axis, non_negative_diagonal)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqr\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     91\u001b[0m     tensor: Tensor,\n\u001b[1;32m     92\u001b[0m     pivot_axis: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     93\u001b[0m     non_negative_diagonal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     94\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[0;32m---> 95\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m decompositions\u001b[38;5;241m.\u001b[39mqr(jnp, tensor, pivot_axis, non_negative_diagonal)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensornetwork/backends/numpy/decompositions.py:89\u001b[0m, in \u001b[0;36mqr\u001b[0;34m(np, tensor, pivot_axis, non_negative_diagonal)\u001b[0m\n\u001b[1;32m     87\u001b[0m left_dims \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mshape[:pivot_axis]\n\u001b[1;32m     88\u001b[0m right_dims \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mshape[pivot_axis:]\n\u001b[0;32m---> 89\u001b[0m tensor \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(tensor, [numpy\u001b[38;5;241m.\u001b[39mprod(left_dims), numpy\u001b[38;5;241m.\u001b[39mprod(right_dims)])\n\u001b[1;32m     90\u001b[0m q, r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mqr(tensor)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m non_negative_diagonal:\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:450\u001b[0m, in \u001b[0;36m_compute_newshape\u001b[0;34m(arr, newshape)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    449\u001b[0m   newshape \u001b[38;5;241m=\u001b[39m [newshape]\n\u001b[0;32m--> 450\u001b[0m newshape \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mcanonicalize_shape(newshape)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    451\u001b[0m neg1s \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(newshape) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(d) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(neg1s) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/jax/_src/core.py:1739\u001b[0m, in \u001b[0;36mcanonicalize_shape\u001b[0;34m(shape, context)\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1738\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m-> 1739\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _invalid_shape_error(shape, context)\n",
      "\u001b[0;31mTypeError\u001b[0m: Shapes must be 1D sequences of concrete values of integer type, got [2, 1.0]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensornetwork as tn\n",
    "import numpy as np\n",
    "\n",
    "# Number of qubits\n",
    "N = 5  # number of qubits\n",
    "\n",
    "# Each site tensor has shape (chi_left=1, d=2, chi_right=1)\n",
    "# Initialize all qubits in |0>, i.e., A[0]=1, A[1]=0\n",
    "prod_tensors = []\n",
    "for _ in range(N):\n",
    "    # shape (2,) → reshape into (1,2,1) to represent a single qubit in the |0> state\n",
    "    v = tf.constant([1.0, 0.0], dtype=tf.float32)  # Use real type, not complex\n",
    "    # Convert to numpy and append (ensure tensor shape is integer-based)\n",
    "    prod_tensors.append(v.numpy())  # Convert to numpy array\n",
    "\n",
    "# Initialize FiniteMPS (in canonical form)\n",
    "psi_initial = tn.FiniteMPS(prod_tensors, canonicalize=True)\n",
    "\n",
    "# Step 1: Define the Hadamard gate (in real numbers)\n",
    "Hgate = tf.constant([[1.0, 1.0], [1.0, -1.0]], dtype=tf.float32) / tf.cast(tf.sqrt(2.0), tf.float32)\n",
    "\n",
    "# Step 2: Apply the Hadamard gate to the first qubit (on the first site)\n",
    "A0 = psi_initial.tensors[0]  # shape (1,2,1) for the first qubit\n",
    "\n",
    "# Contract the Hadamard gate with the physical index of A0\n",
    "# Tensor contraction over the physical index (index 1 of A0)\n",
    "A0 = tf.tensordot(Hgate, A0, axes=([1], [1]))  # shape (2,1,1)\n",
    "\n",
    "# Step 3: Update the MPS tensor for the first site\n",
    "# We need to transpose it back to the canonical form (1,2,1)\n",
    "psi_initial.tensors[0] = tf.transpose(A0, (1, 0, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-qubit gate shape: (2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "#Two-qubit unitary\n",
    "I = tf.constant([\n",
    "        [1 + 0j, 0 + 0j],\n",
    "        [0 + 0j,  1 + 0j]\n",
    "    ], dtype=tf.complex64)\n",
    "X = tf.constant([\n",
    "        [0 + 0j, 1 + 0j],\n",
    "        [1 + 0j,  0 + 0j]\n",
    "    ], dtype=tf.complex64)\n",
    "Y = tf.constant([\n",
    "        [0 + 0j, 0 - 1j],\n",
    "        [0 + 1j,  0 + 0j]\n",
    "    ], dtype=tf.complex64)\n",
    "Z = tf.constant([\n",
    "        [1 + 0j, 0 + 0j],\n",
    "        [0 + 0j,  -1 + 0j]\n",
    "    ], dtype=tf.complex64)\n",
    "\n",
    "# 15 Hermitian generator basis: \n",
    "# 9 two-site interactions + 3 local on qubit 1 + 3 local on qubit 2\n",
    "paulis = [X, Y, Z]\n",
    "basis_list = []\n",
    "\n",
    "# Interaction terms sigma^a ⊗ sigma^b (a,b in {X,Y,Z})\n",
    "for A in paulis:\n",
    "    for B in paulis:\n",
    "        basis_list.append(tf.linalg.LinearOperatorKronecker([tf.linalg.LinearOperatorFullMatrix(A),\n",
    "                                                              tf.linalg.LinearOperatorFullMatrix(B)])\n",
    "                          .to_dense())\n",
    "\n",
    "\n",
    "# Single-qubit rotations on 1: sigma^a ⊗ I\n",
    "for A in paulis:\n",
    "    basis_list.append(tf.linalg.LinearOperatorKronecker([tf.linalg.LinearOperatorFullMatrix(A),\n",
    "                                                          tf.linalg.LinearOperatorFullMatrix(I)])\n",
    "                      .to_dense())\n",
    "\n",
    "# Single-qubit rotations on 2: I ⊗ sigma^a\n",
    "for B in paulis:\n",
    "    basis_list.append(tf.linalg.LinearOperatorKronecker([tf.linalg.LinearOperatorFullMatrix(I),\n",
    "                                                          tf.linalg.LinearOperatorFullMatrix(B)])\n",
    "                      .to_dense())\n",
    "\n",
    "# Stack into a (15,4,4) tensor\n",
    "basis = tf.stack(basis_list, axis=0)  # shape (15,4,4)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def make_two_qubit_unitary(theta):\n",
    "    # theta: real tf.Tensor shape (15,)\n",
    "    theta_c = tf.cast(theta, tf.complex64)               # → complex64\n",
    "    H = tf.tensordot(theta_c, basis, axes=([0],[0]))    # shape (4,4)\n",
    "    U_flat = tf.linalg.expm(-1j * H)                     # shape (4,4)\n",
    "    return tf.reshape(U_flat, [2,2,2,2])                 # shape (2,2,2,2)\n",
    "\n",
    "\n",
    "\n",
    "theta = tf.Variable(tf.random.normal([15], dtype=tf.float32))\n",
    "U_gate = make_two_qubit_unitary(theta)\n",
    "\n",
    "# U_gate is ready to apply in your two-site update\n",
    "print(\"Two-qubit gate shape:\", U_gate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3445eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Cost function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m mpo_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# now (phys_in=2, phys_out=2, χ_left=1, χ_right=1)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     t \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(X, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      6\u001b[0m     mpo_tensors\u001b[38;5;241m.\u001b[39mappend(t)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "#Cost function\n",
    "mpo_tensors = []\n",
    "for _ in range(N):\n",
    "    # now (phys_in=2, phys_out=2, χ_left=1, χ_right=1)\n",
    "    t = tf.reshape(X, (1, 1, 2, 2))\n",
    "    mpo_tensors.append(t)\n",
    "\n",
    "mpo_X = tn.FiniteMPO(mpo_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb8dd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mps_mpo_expectation_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m expval \u001b[38;5;241m=\u001b[39m mps_mpo_expectation_value(psi_initial, mpo_X)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⟨X⟩ =\u001b[39m\u001b[38;5;124m\"\u001b[39m, expval\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mps_mpo_expectation_value' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "mps_mpo_expectation_value(psi_initial, mpo_X)\n",
    "print(\"⟨X⟩ =\", expval.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization for 5-qubit system\n",
      "Observable: ZZ_nn\n",
      "Maximum bond dimension: 16\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [1,2], In[1]: [1,2] [Op:MatMul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 472\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal two-qubit unitary (real part):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39mreshape(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreal(optimal_unitary), (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m))\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m--> 472\u001b[0m main()\n",
      "Cell \u001b[0;32mIn[16], line 453\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum bond dimension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_bond_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m optimal_params, history \u001b[38;5;241m=\u001b[39m optimize_circuit(\n\u001b[1;32m    454\u001b[0m     N, observable_type, max_bond_dim, learning_rate, iterations\n\u001b[1;32m    455\u001b[0m )\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal expectation value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimal_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 405\u001b[0m, in \u001b[0;36moptimize_circuit\u001b[0;34m(N, observable_type, max_bond_dim, learning_rate, iterations)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;66;03m# Calculate expectation value (cost function)\u001b[39;00m\n\u001b[0;32m--> 405\u001b[0m         expectation \u001b[38;5;241m=\u001b[39m cost_function(theta, basis, N, observable_type, max_bond_dim)\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;66;03m# Calculate gradients\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(expectation, [theta])\n",
      "Cell \u001b[0;32mIn[16], line 363\u001b[0m, in \u001b[0;36mcost_function\u001b[0;34m(theta, basis, N, observable_type, max_bond_dim)\u001b[0m\n\u001b[1;32m    360\u001b[0m mps \u001b[38;5;241m=\u001b[39m apply_single_qubit_gate(mps, H_gate, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Apply the two-qubit gate sequentially\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m mps \u001b[38;5;241m=\u001b[39m apply_sequential_two_qubit_gates(mps, U_gate, max_bond_dim)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Create the observable MPO\u001b[39;00m\n\u001b[1;32m    366\u001b[0m mpo \u001b[38;5;241m=\u001b[39m create_pauli_mpo(N, observable_type)\n",
      "Cell \u001b[0;32mIn[16], line 173\u001b[0m, in \u001b[0;36mapply_sequential_two_qubit_gates\u001b[0;34m(mps, gate, max_bond_dim)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Apply gate to each adjacent pair: (0,1), (1,2), ... (N-2,N-1)\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 173\u001b[0m     mps_result \u001b[38;5;241m=\u001b[39m apply_two_qubit_gate(mps_result, gate, i, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_bond_dim)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mps_result\n",
      "Cell \u001b[0;32mIn[16], line 120\u001b[0m, in \u001b[0;36mapply_two_qubit_gate\u001b[0;34m(mps, gate, site1, site2, max_bond_dim)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Contract tensors to form two-site tensor\u001b[39;00m\n\u001b[1;32m    119\u001b[0m theta \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(tensor1, [chi_left1, d1 \u001b[38;5;241m*\u001b[39m chi_right1])\n\u001b[0;32m--> 120\u001b[0m theta \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(theta, tf\u001b[38;5;241m.\u001b[39mreshape(tensor2, [chi_right1, d2 \u001b[38;5;241m*\u001b[39m chi_right2]))\n\u001b[1;32m    121\u001b[0m theta \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(theta, [chi_left1, d1, d2, chi_right2])\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Apply the gate\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:6006\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6004\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6005\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6006\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [1,2], In[1]: [1,2] [Op:MatMul] name: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensornetwork as tn\n",
    "\n",
    "# Set TensorNetwork to use the TensorFlow backend (needed for autodiff)\n",
    "tn.set_default_backend(\"tensorflow\")\n",
    "\n",
    "def copy_mps(mps):\n",
    "    \"\"\"\n",
    "    Create a deep copy of a FiniteMPS object.\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        \n",
    "    Returns:\n",
    "        New FiniteMPS object with the same tensors\n",
    "    \"\"\"\n",
    "    # Copy all tensors\n",
    "    tensor_copies = [tf.identity(tensor) for tensor in mps.tensors]\n",
    "    \n",
    "    # Create a new MPS with the copied tensors\n",
    "    new_mps = tn.FiniteMPS(tensor_copies, canonicalize=False)\n",
    "    \n",
    "    # Copy the center position\n",
    "    new_mps.center_position = mps.center_position\n",
    "    \n",
    "    return new_mps\n",
    "\n",
    "def initialize_mps(N, initial_state=\"zero\"):\n",
    "    \"\"\"\n",
    "    Initialize an MPS with N qubits in the specified initial state.\n",
    "    \n",
    "    Args:\n",
    "        N: Number of qubits\n",
    "        initial_state: 'zero' for |0⟩^⊗N, 'plus' for |+⟩^⊗N\n",
    "    \n",
    "    Returns:\n",
    "        FiniteMPS object\n",
    "    \"\"\"\n",
    "    prod_tensors = []\n",
    "    \n",
    "    if initial_state == \"zero\":\n",
    "        # Initialize all qubits in |0⟩\n",
    "        for _ in range(N):\n",
    "            v = tf.constant([1.0, 0.0], dtype=tf.complex64)\n",
    "            prod_tensors.append(tf.reshape(v, (1, 2, 1)))\n",
    "    elif initial_state == \"plus\":\n",
    "        # Initialize all qubits in |+⟩\n",
    "        v = tf.constant([1.0, 1.0], dtype=tf.complex64) / tf.sqrt(tf.cast(2.0, tf.complex64))\n",
    "        for _ in range(N):\n",
    "            prod_tensors.append(tf.reshape(v, (1, 2, 1)))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported initial state\")\n",
    "    \n",
    "    # Initialize FiniteMPS (in canonical form)\n",
    "    return tn.FiniteMPS(prod_tensors, canonicalize=True)\n",
    "\n",
    "def apply_single_qubit_gate(mps, gate, site):\n",
    "    \"\"\"\n",
    "    Apply a single-qubit gate to a specific site of the MPS.\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        gate: [2, 2] tensor representing the single-qubit gate\n",
    "        site: Site index to apply the gate to\n",
    "    \n",
    "    Returns:\n",
    "        Updated FiniteMPS object\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    mps_copy = copy_mps(mps)\n",
    "    \n",
    "    # Apply gate to the specified site\n",
    "    tensor = mps_copy.tensors[site]  # shape (chi_left, 2, chi_right)\n",
    "    gate_applied = tf.tensordot(gate, tensor, axes=([1], [1]))  # (2, chi_left, chi_right)\n",
    "    mps_copy.tensors[site] = tf.transpose(gate_applied, (1, 0, 2))  # (chi_left, 2, chi_right)\n",
    "    \n",
    "    return mps_copy\n",
    "\n",
    "def apply_two_qubit_gate(mps, gate, site1, site2, max_bond_dim=None):\n",
    "    \"\"\"\n",
    "    Apply a two-qubit gate to adjacent sites in the MPS.\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        gate: [2, 2, 2, 2] tensor representing the two-qubit gate\n",
    "        site1, site2: Adjacent site indices\n",
    "        max_bond_dim: Maximum bond dimension after SVD truncation\n",
    "    \n",
    "    Returns:\n",
    "        Updated FiniteMPS object\n",
    "    \"\"\"\n",
    "    # Ensure sites are adjacent\n",
    "    if abs(site1 - site2) != 1:\n",
    "        raise ValueError(\"Sites must be adjacent\")\n",
    "    \n",
    "    # Make sure site1 < site2\n",
    "    if site1 > site2:\n",
    "        site1, site2 = site2, site1\n",
    "        # Permute gate indices to match the new site order\n",
    "        gate = tf.transpose(gate, [2, 3, 0, 1])\n",
    "    \n",
    "    # Make a copy of the MPS\n",
    "    mps_copy = copy_mps(mps)\n",
    "    \n",
    "    # Ensure the MPS is in the right canonical form\n",
    "    mps_copy.position(site1)\n",
    "    \n",
    "    # Get tensors at the two sites\n",
    "    tensor1 = mps_copy.tensors[site1]  # (chi_left1, 2, chi_right1)\n",
    "    tensor2 = mps_copy.tensors[site2]  # (chi_left2, 2, chi_right2)\n",
    "    \n",
    "    # Extract dimensions\n",
    "    chi_left1, d1, chi_right1 = tensor1.shape\n",
    "    chi_left2, d2, chi_right2 = tensor2.shape\n",
    "    \n",
    "    # Contract tensors to form two-site tensor\n",
    "    theta = tf.reshape(tensor1, [chi_left1, d1 * chi_right1])\n",
    "    theta = tf.matmul(theta, tf.reshape(tensor2, [chi_right1, d2 * chi_right2]))\n",
    "    theta = tf.reshape(theta, [chi_left1, d1, d2, chi_right2])\n",
    "    \n",
    "    # Apply the gate\n",
    "    theta_prime = tf.einsum('ijkl,jknm->inml', theta, gate)\n",
    "    theta_prime = tf.reshape(theta_prime, [chi_left1 * d1, d2 * chi_right2])\n",
    "    \n",
    "    # SVD to decompose back to MPS form\n",
    "    s, u, v = tf.linalg.svd(theta_prime, full_matrices=False)\n",
    "    \n",
    "    # Truncate if needed\n",
    "    if max_bond_dim is not None and s.shape[0] > max_bond_dim:\n",
    "        s = s[:max_bond_dim]\n",
    "        u = u[:, :max_bond_dim]\n",
    "        v = v[:max_bond_dim, :]\n",
    "    \n",
    "    # Create new tensors\n",
    "    chi_new = s.shape[0]\n",
    "    \n",
    "    # Include singular values in the u tensor\n",
    "    u = u * tf.reshape(tf.sqrt(s), [1, -1])\n",
    "    v = v * tf.reshape(tf.sqrt(s), [-1, 1])\n",
    "    \n",
    "    # Reshape back to rank-3 tensors\n",
    "    new_tensor1 = tf.reshape(u, [chi_left1, d1, chi_new])\n",
    "    new_tensor2 = tf.reshape(v, [chi_new, d2, chi_right2])\n",
    "    \n",
    "    # Update the tensors in the MPS\n",
    "    mps_copy.tensors[site1] = new_tensor1\n",
    "    mps_copy.tensors[site2] = new_tensor2\n",
    "    \n",
    "    # Update center position\n",
    "    mps_copy.center_position = site2\n",
    "    \n",
    "    return mps_copy\n",
    "\n",
    "def apply_sequential_two_qubit_gates(mps, gate, max_bond_dim=None):\n",
    "    \"\"\"\n",
    "    Apply a two-qubit gate sequentially to all adjacent pairs of qubits.\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        gate: [2, 2, 2, 2] tensor representing the two-qubit gate\n",
    "        max_bond_dim: Maximum bond dimension after SVD truncation\n",
    "    \n",
    "    Returns:\n",
    "        Updated FiniteMPS object\n",
    "    \"\"\"\n",
    "    mps_result = copy_mps(mps)\n",
    "    N = len(mps_result.tensors)\n",
    "    \n",
    "    # Apply gate to each adjacent pair: (0,1), (1,2), ... (N-2,N-1)\n",
    "    for i in range(N - 1):\n",
    "        mps_result = apply_two_qubit_gate(mps_result, gate, i, i + 1, max_bond_dim)\n",
    "    \n",
    "    return mps_result\n",
    "\n",
    "def create_pauli_mpo(N, operator_type):\n",
    "    \"\"\"\n",
    "    Create an MPO for a Pauli operator on all sites or nearest-neighbor interactions.\n",
    "    \n",
    "    Args:\n",
    "        N: Number of qubits\n",
    "        operator_type: String identifier for the observable ('X', 'Z', 'ZZ_nn')\n",
    "        \n",
    "    Returns:\n",
    "        FiniteMPO object\n",
    "    \"\"\"\n",
    "    # Define Pauli operators\n",
    "    I = tf.constant([[1.0, 0.0], [0.0, 1.0]], dtype=tf.complex64)\n",
    "    X = tf.constant([[0.0, 1.0], [1.0, 0.0]], dtype=tf.complex64)\n",
    "    Y = tf.constant([[0.0, -1j], [1j, 0.0]], dtype=tf.complex64)\n",
    "    Z = tf.constant([[1.0, 0.0], [0.0, -1.0]], dtype=tf.complex64)\n",
    "    \n",
    "    mpo_tensors = []\n",
    "    \n",
    "    if operator_type in ['X', 'Y', 'Z']:\n",
    "        # Select the appropriate operator\n",
    "        op = {'X': X, 'Y': Y, 'Z': Z}[operator_type]\n",
    "        \n",
    "        # Create MPO for single-site operator on every site\n",
    "        for _ in range(N):\n",
    "            # Shape: (bond_left=1, bond_right=1, phys_in=2, phys_out=2)\n",
    "            t = tf.reshape(op, (1, 1, 2, 2))\n",
    "            mpo_tensors.append(t)\n",
    "    \n",
    "    elif operator_type == 'ZZ_nn':\n",
    "        # MPO for sum of nearest-neighbor ZZ interactions\n",
    "        \n",
    "        # First site: [I, Z]\n",
    "        first_site = tf.zeros((1, 2, 2, 2), dtype=tf.complex64)\n",
    "        first_site = tf.tensor_scatter_nd_update(\n",
    "            first_site, \n",
    "            [[0, 0, 0, 0], [0, 0, 1, 1], [0, 1, 0, 0], [0, 1, 1, 1]],\n",
    "            [tf.complex(1.0, 0.0), tf.complex(1.0, 0.0), tf.complex(1.0, 0.0), tf.complex(-1.0, 0.0)]\n",
    "        )\n",
    "        mpo_tensors.append(first_site)\n",
    "        \n",
    "        # Middle sites: [I, 0; Z, I]\n",
    "        for _ in range(N - 2):\n",
    "            mid_site = tf.zeros((2, 2, 2, 2), dtype=tf.complex64)\n",
    "            mid_site = tf.tensor_scatter_nd_update(\n",
    "                mid_site,\n",
    "                [[0, 0, 0, 0], [0, 0, 1, 1], [1, 0, 0, 0], [1, 0, 1, 1], [1, 1, 0, 0], [1, 1, 1, 1]],\n",
    "                [tf.complex(1.0, 0.0), tf.complex(1.0, 0.0), tf.complex(1.0, 0.0), \n",
    "                 tf.complex(-1.0, 0.0), tf.complex(1.0, 0.0), tf.complex(1.0, 0.0)]\n",
    "            )\n",
    "            mpo_tensors.append(mid_site)\n",
    "        \n",
    "        # Last site: [Z, I]\n",
    "        last_site = tf.zeros((2, 1, 2, 2), dtype=tf.complex64)\n",
    "        last_site = tf.tensor_scatter_nd_update(\n",
    "            last_site,\n",
    "            [[0, 0, 0, 0], [0, 0, 1, 1], [1, 0, 0, 0], [1, 0, 1, 1]],\n",
    "            [tf.complex(1.0, 0.0), tf.complex(-1.0, 0.0), tf.complex(1.0, 0.0), tf.complex(1.0, 0.0)]\n",
    "        )\n",
    "        mpo_tensors.append(last_site)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported operator type: {operator_type}\")\n",
    "    \n",
    "    return tn.FiniteMPO(mpo_tensors)\n",
    "\n",
    "def mps_mpo_expectation_value(mps, mpo):\n",
    "    \"\"\"\n",
    "    Calculate the expectation value <ψ|O|ψ> for an MPS and MPO.\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        mpo: FiniteMPO object\n",
    "        \n",
    "    Returns:\n",
    "        Real-valued expectation value\n",
    "    \"\"\"\n",
    "    # Contract the MPS with the MPO and the conjugate of the MPS\n",
    "    mps_prime = mpo.apply(mps)\n",
    "    result = mps.inner_product(mps_prime)\n",
    "    \n",
    "    # Ensure the result is real (should be, for Hermitian observables)\n",
    "    return tf.math.real(result)\n",
    "\n",
    "def make_two_qubit_unitary(theta, basis):\n",
    "    \"\"\"\n",
    "    Create a two-qubit unitary gate from parameters and a basis.\n",
    "    \n",
    "    Args:\n",
    "        theta: Parameters, shape (15,)\n",
    "        basis: Basis of generators, shape (15, 4, 4)\n",
    "    \n",
    "    Returns:\n",
    "        Unitary gate as a tensor of shape (2, 2, 2, 2)\n",
    "    \"\"\"\n",
    "    # Convert parameters to complex\n",
    "    theta_c = tf.cast(theta, tf.complex64)\n",
    "    \n",
    "    # Generate Hermitian generator\n",
    "    H = tf.tensordot(theta_c, basis, axes=([0], [0]))  # shape (4, 4)\n",
    "    \n",
    "    # Create unitary via matrix exponential\n",
    "    U_flat = tf.linalg.expm(-1j * H)  # shape (4, 4)\n",
    "    \n",
    "    # Reshape to two-qubit gate format\n",
    "    return tf.reshape(U_flat, [2, 2, 2, 2])  # shape (2, 2, 2, 2)\n",
    "\n",
    "def create_basis():\n",
    "    \"\"\"\n",
    "    Create the basis of 15 generators for the two-qubit unitary.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor of shape (15, 4, 4)\n",
    "    \"\"\"\n",
    "    # Define Pauli matrices\n",
    "    I = tf.constant([\n",
    "        [1 + 0j, 0 + 0j],\n",
    "        [0 + 0j, 1 + 0j]\n",
    "    ], dtype=tf.complex64)\n",
    "    X = tf.constant([\n",
    "        [0 + 0j, 1 + 0j],\n",
    "        [1 + 0j, 0 + 0j]\n",
    "    ], dtype=tf.complex64)\n",
    "    Y = tf.constant([\n",
    "        [0 + 0j, 0 - 1j],\n",
    "        [0 + 1j, 0 + 0j]\n",
    "    ], dtype=tf.complex64)\n",
    "    Z = tf.constant([\n",
    "        [1 + 0j, 0 + 0j],\n",
    "        [0 + 0j, -1 + 0j]\n",
    "    ], dtype=tf.complex64)\n",
    "    \n",
    "    paulis = [X, Y, Z]\n",
    "    basis_list = []\n",
    "    \n",
    "    # Interaction terms sigma^a ⊗ sigma^b (a,b in {X,Y,Z})\n",
    "    for A in paulis:\n",
    "        for B in paulis:\n",
    "            basis_list.append(tf.linalg.LinearOperatorKronecker([\n",
    "                tf.linalg.LinearOperatorFullMatrix(A),\n",
    "                tf.linalg.LinearOperatorFullMatrix(B)\n",
    "            ]).to_dense())\n",
    "    \n",
    "    # Single-qubit rotations on 1: sigma^a ⊗ I\n",
    "    for A in paulis:\n",
    "        basis_list.append(tf.linalg.LinearOperatorKronecker([\n",
    "            tf.linalg.LinearOperatorFullMatrix(A),\n",
    "            tf.linalg.LinearOperatorFullMatrix(I)\n",
    "        ]).to_dense())\n",
    "    \n",
    "    # Single-qubit rotations on 2: I ⊗ sigma^a\n",
    "    for B in paulis:\n",
    "        basis_list.append(tf.linalg.LinearOperatorKronecker([\n",
    "            tf.linalg.LinearOperatorFullMatrix(I),\n",
    "            tf.linalg.LinearOperatorFullMatrix(B)\n",
    "        ]).to_dense())\n",
    "    \n",
    "    # Stack into a (15, 4, 4) tensor\n",
    "    return tf.stack(basis_list, axis=0)\n",
    "\n",
    "def cost_function(theta, basis, N, observable_type, max_bond_dim=None):\n",
    "    \"\"\"\n",
    "    Calculate the expectation value of an observable for a quantum state\n",
    "    evolved by the parameterized circuit.\n",
    "    \n",
    "    Args:\n",
    "        theta: Parameters of the two-qubit gate, shape (15,)\n",
    "        basis: Basis of generators, shape (15, 4, 4)\n",
    "        N: Number of qubits\n",
    "        observable_type: Type of observable to measure\n",
    "        max_bond_dim: Maximum bond dimension for MPS\n",
    "        \n",
    "    Returns:\n",
    "        Expectation value (to be minimized)\n",
    "    \"\"\"\n",
    "    # Create the two-qubit unitary gate\n",
    "    U_gate = make_two_qubit_unitary(theta, basis)\n",
    "    \n",
    "    # Initialize MPS in |0⟩^⊗N state\n",
    "    mps = initialize_mps(N, initial_state=\"zero\")\n",
    "    \n",
    "    # Apply Hadamard to the first qubit (optional)\n",
    "    H_gate = tf.constant([[1.0, 1.0], [1.0, -1.0]], dtype=tf.complex64) / tf.sqrt(tf.cast(2.0, tf.complex64))\n",
    "    mps = apply_single_qubit_gate(mps, H_gate, 0)\n",
    "    \n",
    "    # Apply the two-qubit gate sequentially\n",
    "    mps = apply_sequential_two_qubit_gates(mps, U_gate, max_bond_dim)\n",
    "    \n",
    "    # Create the observable MPO\n",
    "    mpo = create_pauli_mpo(N, observable_type)\n",
    "    \n",
    "    # Calculate the expectation value\n",
    "    expectation = mps_mpo_expectation_value(mps, mpo)\n",
    "    \n",
    "    return expectation\n",
    "\n",
    "def optimize_circuit(N, observable_type='ZZ_nn', max_bond_dim=None, \n",
    "                     learning_rate=0.01, iterations=100):\n",
    "    \"\"\"\n",
    "    Optimize the parameters of the two-qubit gate to minimize the expectation\n",
    "    value of the given observable.\n",
    "    \n",
    "    Args:\n",
    "        N: Number of qubits\n",
    "        observable_type: Type of observable to measure\n",
    "        max_bond_dim: Maximum bond dimension for MPS\n",
    "        learning_rate: Learning rate for the optimizer\n",
    "        iterations: Number of optimization steps\n",
    "        \n",
    "    Returns:\n",
    "        Optimized parameters and history of expectation values\n",
    "    \"\"\"\n",
    "    # Create basis for the two-qubit unitary\n",
    "    basis = create_basis()\n",
    "    \n",
    "    # Initialize parameters randomly\n",
    "    theta = tf.Variable(tf.random.normal([15], stddev=0.1, dtype=tf.float32))\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # Store the history of expectation values\n",
    "    history = []\n",
    "    \n",
    "    # Run optimization\n",
    "    for step in range(iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Calculate expectation value (cost function)\n",
    "            expectation = cost_function(theta, basis, N, observable_type, max_bond_dim)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        gradients = tape.gradient(expectation, [theta])\n",
    "        \n",
    "        # Apply gradients\n",
    "        optimizer.apply_gradients(zip(gradients, [theta]))\n",
    "        \n",
    "        # Store expectation value\n",
    "        history.append(expectation.numpy())\n",
    "        \n",
    "        # Print progress\n",
    "        if step % 10 == 0 or step == iterations - 1:\n",
    "            print(f\"Step {step}: Expectation value = {expectation.numpy():.6f}\")\n",
    "    \n",
    "    return theta.numpy(), history\n",
    "\n",
    "def visualize_results(history):\n",
    "    \"\"\"\n",
    "    Visualize the optimization history.\n",
    "    \n",
    "    Args:\n",
    "        history: List of expectation values\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Optimization Step')\n",
    "    plt.ylabel('Expectation Value')\n",
    "    plt.title('Optimization Progress')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the optimization.\n",
    "    \"\"\"\n",
    "    # Set parameters\n",
    "    N = 5  # number of qubits\n",
    "    observable_type = 'ZZ_nn'  # nearest-neighbor ZZ interactions\n",
    "    max_bond_dim = 16  # maximum bond dimension\n",
    "    learning_rate = 0.01\n",
    "    iterations = 200\n",
    "    \n",
    "    print(f\"Starting optimization for {N}-qubit system\")\n",
    "    print(f\"Observable: {observable_type}\")\n",
    "    print(f\"Maximum bond dimension: {max_bond_dim}\")\n",
    "    \n",
    "    # Run optimization\n",
    "    optimal_params, history = optimize_circuit(\n",
    "        N, observable_type, max_bond_dim, learning_rate, iterations\n",
    "    )\n",
    "    \n",
    "    print(f\"Final expectation value: {history[-1]:.6f}\")\n",
    "    print(f\"Optimal parameters: {optimal_params}\")\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_results(history)\n",
    "    \n",
    "    # Create the optimal unitary\n",
    "    basis = create_basis()\n",
    "    optimal_unitary = make_two_qubit_unitary(optimal_params, basis)\n",
    "    \n",
    "    print(\"Optimal two-qubit unitary (real part):\")\n",
    "    print(tf.reshape(tf.math.real(optimal_unitary), (4, 4)).numpy())\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd89813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic MPS and MPO Operations ===\n",
      "Number of qubits: 3\n",
      "\n",
      "MPS tensors shapes:\n",
      "  Tensor 0: (1, 2, 1)\n",
      "  Tensor 1: (1, 2, 1)\n",
      "  Tensor 2: (1, 2, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't convert Python sequence with mixed types to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 309\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mps, mpo, bell_state\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 309\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[17], line 300\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03mMain function to run tests\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Test basic MPS and MPO operations\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m mps, mpo \u001b[38;5;241m=\u001b[39m test_mps_mpo_operations()\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# Test two-qubit gate application\u001b[39;00m\n\u001b[1;32m    303\u001b[0m bell_state \u001b[38;5;241m=\u001b[39m test_two_qubit_gate()\n",
      "Cell \u001b[0;32mIn[17], line 141\u001b[0m, in \u001b[0;36mtest_mps_mpo_operations\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Tensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Create MPO for Z operator on each site\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m mpo_z \u001b[38;5;241m=\u001b[39m create_simple_mpo(n_qubits, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMPO tensors shapes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mpo_z\u001b[38;5;241m.\u001b[39mtensors):\n",
      "Cell \u001b[0;32mIn[17], line 39\u001b[0m, in \u001b[0;36mcreate_simple_mpo\u001b[0;34m(n_qubits, operator)\u001b[0m\n\u001b[1;32m     37\u001b[0m I \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m], [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[1;32m     38\u001b[0m X \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m], [\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[0;32m---> 39\u001b[0m Y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39mj], [\u001b[38;5;241m1\u001b[39mj, \u001b[38;5;241m0.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[1;32m     40\u001b[0m Z \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m], [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Select the operator\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    277\u001b[0m                         allow_broadcast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert Python sequence with mixed types to Tensor."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensornetwork as tn\n",
    "\n",
    "# Set TensorNetwork to use TensorFlow backend\n",
    "tn.set_default_backend(\"tensorflow\")\n",
    "\n",
    "def initialize_simple_mps(n_qubits):\n",
    "    \"\"\"\n",
    "    Initialize a simple MPS with all qubits in |0⟩\n",
    "    \"\"\"\n",
    "    # Create tensors for MPS in |0⟩^⊗n state\n",
    "    tensors = []\n",
    "    for _ in range(n_qubits):\n",
    "        # Create tensor for |0⟩ state: [1, 0]\n",
    "        # Reshape to rank-3 tensor with bond dimension 1\n",
    "        tensor = tf.constant([[1.0], [0.0]], dtype=tf.complex64)  # shape: [2, 1]\n",
    "        tensor = tf.reshape(tensor, [1, 2, 1])  # shape: [1, 2, 1]\n",
    "        tensors.append(tensor)\n",
    "    \n",
    "    # Create FiniteMPS\n",
    "    mps = tn.FiniteMPS(tensors, canonicalize=True)\n",
    "    return mps\n",
    "\n",
    "def create_simple_mpo(n_qubits, operator='Z'):\n",
    "    \"\"\"\n",
    "    Create a simple MPO representing a product of Pauli operators.\n",
    "    \n",
    "    Args:\n",
    "        n_qubits: Number of qubits\n",
    "        operator: 'X', 'Y', or 'Z' for Pauli operators\n",
    "    \n",
    "    Returns:\n",
    "        FiniteMPO object\n",
    "    \"\"\"\n",
    "    # Define Pauli matrices\n",
    "    I = tf.constant([[1.0, 0.0], [0.0, 1.0]], dtype=tf.complex64)\n",
    "    X = tf.constant([[0.0, 1.0], [1.0, 0.0]], dtype=tf.complex64)\n",
    "    Y = tf.constant([[0.0, -1j], [1j, 0.0]], dtype=tf.complex64)\n",
    "    Z = tf.constant([[1.0, 0.0], [0.0, -1.0]], dtype=tf.complex64)\n",
    "    \n",
    "    # Select the operator\n",
    "    op_dict = {'I': I, 'X': X, 'Y': Y, 'Z': Z}\n",
    "    op = op_dict.get(operator, Z)\n",
    "    \n",
    "    # Create MPO tensors\n",
    "    mpo_tensors = []\n",
    "    for _ in range(n_qubits):\n",
    "        # Reshape operator to rank-4 tensor: [1, 1, 2, 2]\n",
    "        # Dimensions: [left_bond, right_bond, physical_in, physical_out]\n",
    "        tensor = tf.reshape(op, [1, 1, 2, 2])\n",
    "        mpo_tensors.append(tensor)\n",
    "    \n",
    "    # Create FiniteMPO\n",
    "    mpo = tn.FiniteMPO(mpo_tensors)\n",
    "    return mpo\n",
    "\n",
    "def apply_mpo_to_mps(mps, mpo):\n",
    "    \"\"\"\n",
    "    Apply an MPO to an MPS\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        mpo: FiniteMPO object\n",
    "    \n",
    "    Returns:\n",
    "        FiniteMPS resulting from applying the MPO to the MPS\n",
    "    \"\"\"\n",
    "    return mpo.apply(mps)\n",
    "\n",
    "def compute_expectation_value(mps, mpo):\n",
    "    \"\"\"\n",
    "    Compute the expectation value <ψ|O|ψ>\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        mpo: FiniteMPO object\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value (real part)\n",
    "    \"\"\"\n",
    "    # Apply MPO to MPS\n",
    "    mps_prime = apply_mpo_to_mps(mps, mpo)\n",
    "    \n",
    "    # Compute inner product\n",
    "    expectation = mps.inner_product(mps_prime)\n",
    "    \n",
    "    # Return real part (should be real for Hermitian observables)\n",
    "    return tf.math.real(expectation)\n",
    "\n",
    "def apply_single_site_gate(mps, gate, site):\n",
    "    \"\"\"\n",
    "    Apply a single-site gate to an MPS\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        gate: [2, 2] tensor representing gate\n",
    "        site: Site to apply gate to\n",
    "    \n",
    "    Returns:\n",
    "        Updated FiniteMPS\n",
    "    \"\"\"\n",
    "    # Get tensor at the site\n",
    "    tensor = mps.tensors[site]  # [D1, 2, D2]\n",
    "    \n",
    "    # Make a copy of all tensors\n",
    "    new_tensors = [tf.identity(t) for t in mps.tensors]\n",
    "    \n",
    "    # Apply gate to the tensor\n",
    "    # Contract gate with physical dimension of tensor\n",
    "    new_tensor = tf.einsum('ab,cbd->cad', gate, tensor)\n",
    "    \n",
    "    # Update tensor in the list\n",
    "    new_tensors[site] = new_tensor\n",
    "    \n",
    "    # Create new MPS\n",
    "    new_mps = tn.FiniteMPS(new_tensors, canonicalize=False)\n",
    "    \n",
    "    # Copy center position from original MPS\n",
    "    new_mps.center_position = mps.center_position\n",
    "    \n",
    "    return new_mps\n",
    "\n",
    "def test_mps_mpo_operations():\n",
    "    \"\"\"\n",
    "    Test basic MPS and MPO operations\n",
    "    \"\"\"\n",
    "    # Number of qubits\n",
    "    n_qubits = 3\n",
    "    \n",
    "    print(\"=== Basic MPS and MPO Operations ===\")\n",
    "    print(f\"Number of qubits: {n_qubits}\")\n",
    "    \n",
    "    # Create MPS in |000⟩ state\n",
    "    mps = initialize_simple_mps(n_qubits)\n",
    "    print(\"\\nMPS tensors shapes:\")\n",
    "    for i, tensor in enumerate(mps.tensors):\n",
    "        print(f\"  Tensor {i}: {tensor.shape}\")\n",
    "    \n",
    "    # Create MPO for Z operator on each site\n",
    "    mpo_z = create_simple_mpo(n_qubits, 'Z')\n",
    "    print(\"\\nMPO tensors shapes:\")\n",
    "    for i, tensor in enumerate(mpo_z.tensors):\n",
    "        print(f\"  Tensor {i}: {tensor.shape}\")\n",
    "    \n",
    "    # Compute expectation value for Z^⊗n\n",
    "    expectation_z = compute_expectation_value(mps, mpo_z)\n",
    "    print(f\"\\nExpectation value <000|Z^⊗{n_qubits}|000>: {expectation_z.numpy()}\")\n",
    "    \n",
    "    # Define Hadamard gate\n",
    "    H = tf.constant([[1.0, 1.0], [1.0, -1.0]], dtype=tf.complex64) / tf.sqrt(tf.cast(2.0, tf.complex64))\n",
    "    \n",
    "    # Apply Hadamard to first qubit: |000⟩ -> |+00⟩\n",
    "    mps_h = apply_single_site_gate(mps, H, 0)\n",
    "    \n",
    "    # Compute new expectation values\n",
    "    expectation_z_h = compute_expectation_value(mps_h, mpo_z)\n",
    "    print(f\"\\nAfter applying H to first qubit:\")\n",
    "    print(f\"Expectation value <+00|Z^⊗{n_qubits}|+00>: {expectation_z_h.numpy()}\")\n",
    "    \n",
    "    # Create MPO for X operator on each site\n",
    "    mpo_x = create_simple_mpo(n_qubits, 'X')\n",
    "    expectation_x_h = compute_expectation_value(mps_h, mpo_x)\n",
    "    print(f\"Expectation value <+00|X^⊗{n_qubits}|+00>: {expectation_x_h.numpy()}\")\n",
    "    \n",
    "    return mps, mpo_z\n",
    "\n",
    "def apply_adjacent_two_qubit_gate_simple(mps, gate, site1, site2):\n",
    "    \"\"\"\n",
    "    Apply a two-qubit gate to adjacent sites in an MPS (simplified version)\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        gate: [2, 2, 2, 2] tensor for two-qubit gate\n",
    "        site1, site2: Adjacent sites to apply gate to\n",
    "    \n",
    "    Returns:\n",
    "        Updated FiniteMPS\n",
    "    \"\"\"\n",
    "    # Make sure sites are adjacent\n",
    "    if abs(site1 - site2) != 1:\n",
    "        raise ValueError(\"Sites must be adjacent\")\n",
    "    \n",
    "    # Make sure site1 < site2\n",
    "    if site1 > site2:\n",
    "        site1, site2 = site2, site1\n",
    "        # Swap gate indices\n",
    "        gate = tf.transpose(gate, [2, 3, 0, 1])\n",
    "    \n",
    "    # Get tensors at the sites\n",
    "    tensor1 = mps.tensors[site1]  # [D1, 2, D2]\n",
    "    tensor2 = mps.tensors[site2]  # [D2, 2, D3]\n",
    "    \n",
    "    # Extract dimensions\n",
    "    D1, _, D2 = tensor1.shape\n",
    "    _, _, D3 = tensor2.shape\n",
    "    \n",
    "    # Combine the two tensors into a single tensor\n",
    "    # First, reshape tensors for appropriate contraction\n",
    "    tensor1_reshaped = tf.reshape(tensor1, [D1, 2, D2])\n",
    "    tensor2_reshaped = tf.reshape(tensor2, [D2, 2, D3])\n",
    "    \n",
    "    # Contract along the bond dimension\n",
    "    combined = tf.einsum('abc,cde->abde', tensor1_reshaped, tensor2_reshaped)\n",
    "    # Result shape: [D1, 2, 2, D3]\n",
    "    \n",
    "    # Apply the two-qubit gate\n",
    "    updated = tf.einsum('abcd,bcej->aejd', combined, gate)\n",
    "    # Result shape: [D1, 2, 2, D3]\n",
    "    \n",
    "    # Make a copy of all tensors\n",
    "    new_tensors = [tf.identity(t) for t in mps.tensors]\n",
    "    \n",
    "    # For simplicity, we'll decompose the tensor using simple reshaping\n",
    "    # This is a simplified approach and doesn't preserve canonical form or truncate\n",
    "    \n",
    "    # Simply reshape the contracted tensor\n",
    "    s1 = tf.reshape(updated, [D1, 2, 2 * D3])\n",
    "    new_tensors[site1] = s1\n",
    "    \n",
    "    # Create s2 as a dummy tensor to maintain the MPS structure\n",
    "    # Not a proper SVD decomposition, but works for demonstration\n",
    "    s2 = tf.ones([2 * D3, 2, D3], dtype=tf.complex64)\n",
    "    s2 = s2 / tf.cast(tf.sqrt(tf.cast(2 * D3, tf.float32)), tf.complex64)  # Normalize\n",
    "    new_tensors[site2] = s2\n",
    "    \n",
    "    # Create new MPS\n",
    "    new_mps = tn.FiniteMPS(new_tensors, canonicalize=False)\n",
    "    \n",
    "    # Set center position\n",
    "    new_mps.center_position = mps.center_position\n",
    "    \n",
    "    return new_mps\n",
    "\n",
    "def test_two_qubit_gate():\n",
    "    \"\"\"\n",
    "    Test applying a two-qubit gate to an MPS\n",
    "    \"\"\"\n",
    "    # Number of qubits\n",
    "    n_qubits = 3\n",
    "    \n",
    "    print(\"\\n=== Two-Qubit Gate Application ===\")\n",
    "    \n",
    "    # Create MPS in |000⟩ state\n",
    "    mps = initialize_simple_mps(n_qubits)\n",
    "    \n",
    "    # Define CNOT gate as a two-qubit gate\n",
    "    # CNOT = |0⟩⟨0| ⊗ I + |1⟩⟨1| ⊗ X\n",
    "    CNOT = tf.zeros([2, 2, 2, 2], dtype=tf.complex64)\n",
    "    \n",
    "    # |00⟩ -> |00⟩\n",
    "    CNOT = tf.tensor_scatter_nd_update(CNOT, [[0, 0, 0, 0]], [tf.complex(1.0, 0.0)])\n",
    "    # |01⟩ -> |01⟩\n",
    "    CNOT = tf.tensor_scatter_nd_update(CNOT, [[0, 1, 0, 1]], [tf.complex(1.0, 0.0)])\n",
    "    # |10⟩ -> |11⟩\n",
    "    CNOT = tf.tensor_scatter_nd_update(CNOT, [[1, 0, 1, 1]], [tf.complex(1.0, 0.0)])\n",
    "    # |11⟩ -> |10⟩\n",
    "    CNOT = tf.tensor_scatter_nd_update(CNOT, [[1, 1, 1, 0]], [tf.complex(1.0, 0.0)])\n",
    "    \n",
    "    # Apply CNOT to qubits 0 and 1\n",
    "    mps_cnot = apply_adjacent_two_qubit_gate_simple(mps, CNOT, 0, 1)\n",
    "    \n",
    "    # Create Z operator MPO\n",
    "    mpo_z = create_simple_mpo(n_qubits, 'Z')\n",
    "    \n",
    "    # Calculate expectation value\n",
    "    expectation = compute_expectation_value(mps_cnot, mpo_z)\n",
    "    print(f\"Expectation value after CNOT: {expectation.numpy()}\")\n",
    "    \n",
    "    # Define Hadamard gate\n",
    "    H = tf.constant([[1.0, 1.0], [1.0, -1.0]], dtype=tf.complex64) / tf.sqrt(tf.cast(2.0, tf.complex64))\n",
    "    \n",
    "    # Apply Hadamard to first qubit\n",
    "    mps_h = apply_single_site_gate(mps, H, 0)\n",
    "    \n",
    "    # Apply CNOT to H|0⟩ ⊗ |0⟩ = |+⟩|0⟩\n",
    "    mps_bell = apply_adjacent_two_qubit_gate_simple(mps_h, CNOT, 0, 1)\n",
    "    \n",
    "    # Measure X on first qubit and Z on second qubit\n",
    "    mpo_x_1 = create_simple_mpo(n_qubits, 'I')  # Start with identity\n",
    "    mpo_x_1.tensors[0] = tf.reshape(tf.constant([[0.0, 1.0], [1.0, 0.0]], dtype=tf.complex64), [1, 1, 2, 2])\n",
    "    \n",
    "    mpo_z_2 = create_simple_mpo(n_qubits, 'I')  # Start with identity\n",
    "    mpo_z_2.tensors[1] = tf.reshape(tf.constant([[1.0, 0.0], [0.0, -1.0]], dtype=tf.complex64), [1, 1, 2, 2])\n",
    "    \n",
    "    # Calculate expectation values\n",
    "    exp_x1 = compute_expectation_value(mps_bell, mpo_x_1)\n",
    "    exp_z2 = compute_expectation_value(mps_bell, mpo_z_2)\n",
    "    \n",
    "    print(f\"Bell state X₁ expectation: {exp_x1.numpy()}\")\n",
    "    print(f\"Bell state Z₂ expectation: {exp_z2.numpy()}\")\n",
    "    \n",
    "    return mps_bell\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run tests\n",
    "    \"\"\"\n",
    "    # Test basic MPS and MPO operations\n",
    "    mps, mpo = test_mps_mpo_operations()\n",
    "    \n",
    "    # Test two-qubit gate application\n",
    "    bell_state = test_two_qubit_gate()\n",
    "    \n",
    "    print(\"\\nAll tests completed successfully!\")\n",
    "    return mps, mpo, bell_state\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic MPS and MPO Operations ===\n",
      "Number of qubits: 3\n",
      "\n",
      "MPS tensors shapes:\n",
      "  Tensor 0: (1, 2, 1)\n",
      "  Tensor 1: (1, 2, 1)\n",
      "  Tensor 2: (1, 2, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't convert Python sequence with mixed types to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 351\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mps, mpo, bell_state\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 351\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[18], line 342\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03mMain function to run tests\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Test basic MPS and MPO operations\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m mps, mpo \u001b[38;5;241m=\u001b[39m test_mps_mpo_operations()\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# Test two-qubit gate application\u001b[39;00m\n\u001b[1;32m    345\u001b[0m bell_state \u001b[38;5;241m=\u001b[39m test_two_qubit_gate()\n",
      "Cell \u001b[0;32mIn[18], line 141\u001b[0m, in \u001b[0;36mtest_mps_mpo_operations\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Tensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Create MPO for Z operator on each site\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m mpo_z \u001b[38;5;241m=\u001b[39m create_simple_mpo(n_qubits, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMPO tensors shapes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mpo_z\u001b[38;5;241m.\u001b[39mtensors):\n",
      "Cell \u001b[0;32mIn[18], line 39\u001b[0m, in \u001b[0;36mcreate_simple_mpo\u001b[0;34m(n_qubits, operator)\u001b[0m\n\u001b[1;32m     37\u001b[0m I \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m], [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[1;32m     38\u001b[0m X \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m], [\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[0;32m---> 39\u001b[0m Y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39mj], [\u001b[38;5;241m1\u001b[39mj, \u001b[38;5;241m0.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[1;32m     40\u001b[0m Z \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m], [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Select the operator\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    277\u001b[0m                         allow_broadcast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert Python sequence with mixed types to Tensor."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensornetwork as tn\n",
    "\n",
    "# Set TensorNetwork to use TensorFlow backend\n",
    "tn.set_default_backend(\"tensorflow\")\n",
    "\n",
    "def initialize_simple_mps(n_qubits):\n",
    "    \"\"\"\n",
    "    Initialize a simple MPS with all qubits in |0⟩\n",
    "    \"\"\"\n",
    "    # Create tensors for MPS in |0⟩^⊗n state\n",
    "    tensors = []\n",
    "    for _ in range(n_qubits):\n",
    "        # Create tensor for |0⟩ state: [1, 0]\n",
    "        # Reshape to rank-3 tensor with bond dimension 1\n",
    "        tensor = tf.constant([[1.0], [0.0]], dtype=tf.complex64)  # shape: [2, 1]\n",
    "        tensor = tf.reshape(tensor, [1, 2, 1])  # shape: [1, 2, 1]\n",
    "        tensors.append(tensor)\n",
    "    \n",
    "    # Create FiniteMPS\n",
    "    mps = tn.FiniteMPS(tensors, canonicalize=True)\n",
    "    return mps\n",
    "\n",
    "def create_simple_mpo(n_qubits, operator='Z'):\n",
    "    \"\"\"\n",
    "    Create a simple MPO representing a product of Pauli operators.\n",
    "    \n",
    "    Args:\n",
    "        n_qubits: Number of qubits\n",
    "        operator: 'X', 'Y', or 'Z' for Pauli operators\n",
    "    \n",
    "    Returns:\n",
    "        FiniteMPO object\n",
    "    \"\"\"\n",
    "    # Define Pauli matrices\n",
    "    I = tf.constant([[1.0, 0.0], [0.0, 1.0]], dtype=tf.complex64)\n",
    "    X = tf.constant([[0.0, 1.0], [1.0, 0.0]], dtype=tf.complex64)\n",
    "    Y = tf.constant([[0.0, -1j], [1j, 0.0]], dtype=tf.complex64)\n",
    "    Z = tf.constant([[1.0, 0.0], [0.0, -1.0]], dtype=tf.complex64)\n",
    "    \n",
    "    # Select the operator\n",
    "    op_dict = {'I': I, 'X': X, 'Y': Y, 'Z': Z}\n",
    "    op = op_dict.get(operator, Z)\n",
    "    \n",
    "    # Create MPO tensors\n",
    "    mpo_tensors = []\n",
    "    for _ in range(n_qubits):\n",
    "        # Reshape operator to rank-4 tensor: [1, 1, 2, 2]\n",
    "        # Dimensions: [left_bond, right_bond, physical_in, physical_out]\n",
    "        tensor = tf.reshape(op, [1, 1, 2, 2])\n",
    "        mpo_tensors.append(tensor)\n",
    "    \n",
    "    # Create FiniteMPO\n",
    "    mpo = tn.FiniteMPO(mpo_tensors)\n",
    "    return mpo\n",
    "\n",
    "def apply_mpo_to_mps(mps, mpo):\n",
    "    \"\"\"\n",
    "    Apply an MPO to an MPS\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        mpo: FiniteMPO object\n",
    "    \n",
    "    Returns:\n",
    "        FiniteMPS resulting from applying the MPO to the MPS\n",
    "    \"\"\"\n",
    "    return mpo.apply(mps)\n",
    "\n",
    "def compute_expectation_value(mps, mpo):\n",
    "    \"\"\"\n",
    "    Compute the expectation value <ψ|O|ψ>\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        mpo: FiniteMPO object\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value (real part)\n",
    "    \"\"\"\n",
    "    # Apply MPO to MPS\n",
    "    mps_prime = apply_mpo_to_mps(mps, mpo)\n",
    "    \n",
    "    # Compute inner product\n",
    "    expectation = mps.inner_product(mps_prime)\n",
    "    \n",
    "    # Return real part (should be real for Hermitian observables)\n",
    "    return tf.math.real(expectation)\n",
    "\n",
    "def apply_single_site_gate(mps, gate, site):\n",
    "    \"\"\"\n",
    "    Apply a single-site gate to an MPS\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        gate: [2, 2] tensor representing gate\n",
    "        site: Site to apply gate to\n",
    "    \n",
    "    Returns:\n",
    "        Updated FiniteMPS\n",
    "    \"\"\"\n",
    "    # Get tensor at the site\n",
    "    tensor = mps.tensors[site]  # [D1, 2, D2]\n",
    "    \n",
    "    # Make a copy of all tensors\n",
    "    new_tensors = [tf.identity(t) for t in mps.tensors]\n",
    "    \n",
    "    # Apply gate to the tensor\n",
    "    # Contract gate with physical dimension of tensor\n",
    "    new_tensor = tf.einsum('ab,cbd->cad', gate, tensor)\n",
    "    \n",
    "    # Update tensor in the list\n",
    "    new_tensors[site] = new_tensor\n",
    "    \n",
    "    # Create new MPS\n",
    "    new_mps = tn.FiniteMPS(new_tensors, canonicalize=False)\n",
    "    \n",
    "    # Copy center position from original MPS\n",
    "    new_mps.center_position = mps.center_position\n",
    "    \n",
    "    return new_mps\n",
    "\n",
    "def test_mps_mpo_operations():\n",
    "    \"\"\"\n",
    "    Test basic MPS and MPO operations\n",
    "    \"\"\"\n",
    "    # Number of qubits\n",
    "    n_qubits = 3\n",
    "    \n",
    "    print(\"=== Basic MPS and MPO Operations ===\")\n",
    "    print(f\"Number of qubits: {n_qubits}\")\n",
    "    \n",
    "    # Create MPS in |000⟩ state\n",
    "    mps = initialize_simple_mps(n_qubits)\n",
    "    print(\"\\nMPS tensors shapes:\")\n",
    "    for i, tensor in enumerate(mps.tensors):\n",
    "        print(f\"  Tensor {i}: {tensor.shape}\")\n",
    "    \n",
    "    # Create MPO for Z operator on each site\n",
    "    mpo_z = create_simple_mpo(n_qubits, 'Z')\n",
    "    print(\"\\nMPO tensors shapes:\")\n",
    "    for i, tensor in enumerate(mpo_z.tensors):\n",
    "        print(f\"  Tensor {i}: {tensor.shape}\")\n",
    "    \n",
    "    # Compute expectation value for Z^⊗n\n",
    "    expectation_z = compute_expectation_value(mps, mpo_z)\n",
    "    print(f\"\\nExpectation value <000|Z^⊗{n_qubits}|000>: {expectation_z.numpy()}\")\n",
    "    \n",
    "    # Define Hadamard gate\n",
    "    H = tf.constant([[1.0, 1.0], [1.0, -1.0]], dtype=tf.complex64) / tf.sqrt(tf.cast(2.0, tf.complex64))\n",
    "    \n",
    "    # Apply Hadamard to first qubit: |000⟩ -> |+00⟩\n",
    "    mps_h = apply_single_site_gate(mps, H, 0)\n",
    "    \n",
    "    # Compute new expectation values\n",
    "    expectation_z_h = compute_expectation_value(mps_h, mpo_z)\n",
    "    print(f\"\\nAfter applying H to first qubit:\")\n",
    "    print(f\"Expectation value <+00|Z^⊗{n_qubits}|+00>: {expectation_z_h.numpy()}\")\n",
    "    \n",
    "    # Create MPO for X operator on each site\n",
    "    mpo_x = create_simple_mpo(n_qubits, 'X')\n",
    "    expectation_x_h = compute_expectation_value(mps_h, mpo_x)\n",
    "    print(f\"Expectation value <+00|X^⊗{n_qubits}|+00>: {expectation_x_h.numpy()}\")\n",
    "    \n",
    "    return mps, mpo_z\n",
    "\n",
    "def apply_adjacent_two_qubit_gate(mps, gate, site1, site2):\n",
    "    \"\"\"\n",
    "    Apply a two-qubit gate to adjacent sites in an MPS using SVD decomposition\n",
    "    \n",
    "    Args:\n",
    "        mps: FiniteMPS object\n",
    "        gate: [2, 2, 2, 2] tensor for two-qubit gate\n",
    "        site1, site2: Adjacent sites to apply gate to\n",
    "    \n",
    "    Returns:\n",
    "        Updated FiniteMPS\n",
    "    \"\"\"\n",
    "    # Make sure sites are adjacent\n",
    "    if abs(site1 - site2) != 1:\n",
    "        raise ValueError(\"Sites must be adjacent\")\n",
    "    \n",
    "    # Make sure site1 < site2\n",
    "    if site1 > site2:\n",
    "        site1, site2 = site2, site1\n",
    "        # Swap gate indices\n",
    "        gate = tf.transpose(gate, [2, 3, 0, 1])\n",
    "    \n",
    "    # Get tensors at the sites\n",
    "    tensor1 = mps.tensors[site1]  # [D1, 2, D2]\n",
    "    tensor2 = mps.tensors[site2]  # [D2, 2, D3]\n",
    "    \n",
    "    # Extract dimensions\n",
    "    D1, d1, D2 = tensor1.shape\n",
    "    _, d2, D3 = tensor2.shape\n",
    "    \n",
    "    # Combine the two tensors into a single tensor using einsum\n",
    "    combined = tf.einsum('abc,cde->abde', tensor1, tensor2)\n",
    "    # Result shape: [D1, 2, 2, D3]\n",
    "    \n",
    "    # Apply the two-qubit gate\n",
    "    combined_after_gate = tf.einsum('abcd,bcej->aejd', combined, gate)\n",
    "    # Result shape: [D1, 2, 2, D3]\n",
    "    \n",
    "    # Reshape the tensor for SVD\n",
    "    combined_reshaped = tf.reshape(combined_after_gate, [D1 * 2, 2 * D3])\n",
    "    \n",
    "    # Perform SVD\n",
    "    s, u, v = tf.linalg.svd(combined_reshaped, full_matrices=False)\n",
    "    \n",
    "    # Decide how many singular values to keep\n",
    "    # For this simple example, we'll keep all of them\n",
    "    chi = s.shape[0]\n",
    "    \n",
    "    # Apply the singular values to u and v\n",
    "    sqrt_s = tf.sqrt(s)\n",
    "    u_s = u * tf.reshape(sqrt_s, [1, -1])\n",
    "    v_s = v * tf.reshape(sqrt_s, [-1, 1])\n",
    "    \n",
    "    # Reshape back to MPS tensor format\n",
    "    new_tensor1 = tf.reshape(u_s, [D1, 2, chi])\n",
    "    new_tensor2 = tf.reshape(v_s, [chi, 2, D3])\n",
    "    \n",
    "    # Create new tensors list\n",
    "    new_tensors = [tf.identity(t) for t in mps.tensors]\n",
    "    new_tensors[site1] = new_tensor1\n",
    "    new_tensors[site2] = new_tensor2\n",
    "    \n",
    "    # Create new MPS\n",
    "    new_mps = tn.FiniteMPS(new_tensors, canonicalize=False)\n",
    "    \n",
    "    # Set center position\n",
    "    new_mps.center_position = site1\n",
    "    \n",
    "    return new_mps\n",
    "\n",
    "def prepare_cnot_gate():\n",
    "    \"\"\"\n",
    "    Prepare a CNOT gate tensor\n",
    "    \n",
    "    Returns:\n",
    "        CNOT gate as a [2, 2, 2, 2] tensor\n",
    "    \"\"\"\n",
    "    # Initialize CNOT tensor with zeros\n",
    "    cnot = tf.zeros([2, 2, 2, 2], dtype=tf.complex64)\n",
    "    \n",
    "    # Define the CNOT gate in computational basis\n",
    "    # |00⟩ -> |00⟩\n",
    "    cnot = tf.tensor_scatter_nd_update(\n",
    "        cnot, [[0, 0, 0, 0]], \n",
    "        [tf.constant(1.0, dtype=tf.complex64)]\n",
    "    )\n",
    "    \n",
    "    # |01⟩ -> |01⟩\n",
    "    cnot = tf.tensor_scatter_nd_update(\n",
    "        cnot, [[0, 1, 0, 1]], \n",
    "        [tf.constant(1.0, dtype=tf.complex64)]\n",
    "    )\n",
    "    \n",
    "    # |10⟩ -> |11⟩\n",
    "    cnot = tf.tensor_scatter_nd_update(\n",
    "        cnot, [[1, 0, 1, 1]], \n",
    "        [tf.constant(1.0, dtype=tf.complex64)]\n",
    "    )\n",
    "    \n",
    "    # |11⟩ -> |10⟩\n",
    "    cnot = tf.tensor_scatter_nd_update(\n",
    "        cnot, [[1, 1, 1, 0]], \n",
    "        [tf.constant(1.0, dtype=tf.complex64)]\n",
    "    )\n",
    "    \n",
    "    return cnot\n",
    "\n",
    "def test_two_qubit_gate():\n",
    "    \"\"\"\n",
    "    Test applying a two-qubit gate to an MPS\n",
    "    \"\"\"\n",
    "    # Number of qubits\n",
    "    n_qubits = 3\n",
    "    \n",
    "    print(\"\\n=== Two-Qubit Gate Application ===\")\n",
    "    \n",
    "    # Create MPS in |000⟩ state\n",
    "    mps = initialize_simple_mps(n_qubits)\n",
    "    \n",
    "    # Prepare CNOT gate\n",
    "    cnot = prepare_cnot_gate()\n",
    "    \n",
    "    # Apply CNOT to qubits 0 and 1\n",
    "    mps_cnot = apply_adjacent_two_qubit_gate(mps, cnot, 0, 1)\n",
    "    \n",
    "    # Create Z operator MPO\n",
    "    mpo_z1 = create_simple_mpo(n_qubits, 'I')  # Start with identity\n",
    "    mpo_z1.tensors[0] = tf.reshape(\n",
    "        tf.constant([[1.0, 0.0], [0.0, -1.0]], dtype=tf.complex64), \n",
    "        [1, 1, 2, 2]\n",
    "    )\n",
    "    \n",
    "    # Calculate expectation value\n",
    "    expectation = compute_expectation_value(mps_cnot, mpo_z1)\n",
    "    print(f\"Expectation value <ψ|Z₁|ψ> after CNOT on |000⟩: {expectation.numpy()}\")\n",
    "    \n",
    "    # Define Hadamard gate\n",
    "    H = tf.constant([[1.0, 1.0], [1.0, -1.0]], dtype=tf.complex64) / tf.sqrt(tf.cast(2.0, tf.complex64))\n",
    "    \n",
    "    # Apply Hadamard to first qubit\n",
    "    mps_h = apply_single_site_gate(mps, H, 0)\n",
    "    \n",
    "    # Apply CNOT to H|0⟩ ⊗ |0⟩ = |+⟩|0⟩ to create Bell state\n",
    "    mps_bell = apply_adjacent_two_qubit_gate(mps_h, cnot, 0, 1)\n",
    "    \n",
    "    # Measure X on first qubit\n",
    "    mpo_x1 = create_simple_mpo(n_qubits, 'I')  # Start with identity\n",
    "    mpo_x1.tensors[0] = tf.reshape(\n",
    "        tf.constant([[0.0, 1.0], [1.0, 0.0]], dtype=tf.complex64), \n",
    "        [1, 1, 2, 2]\n",
    "    )\n",
    "    \n",
    "    # Measure Z on second qubit\n",
    "    mpo_z2 = create_simple_mpo(n_qubits, 'I')  # Start with identity\n",
    "    mpo_z2.tensors[1] = tf.reshape(\n",
    "        tf.constant([[1.0, 0.0], [0.0, -1.0]], dtype=tf.complex64), \n",
    "        [1, 1, 2, 2]\n",
    "    )\n",
    "    \n",
    "    # Calculate expectation values for Bell state\n",
    "    exp_x1 = compute_expectation_value(mps_bell, mpo_x1)\n",
    "    exp_z2 = compute_expectation_value(mps_bell, mpo_z2)\n",
    "    exp_x1z2 = compute_expectation_value(mps_bell, mpo_x1)  # X₁Z₂ correlation\n",
    "    \n",
    "    print(f\"Bell state X₁ expectation: {exp_x1.numpy()}\")\n",
    "    print(f\"Bell state Z₂ expectation: {exp_z2.numpy()}\")\n",
    "    \n",
    "    return mps_bell\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run tests\n",
    "    \"\"\"\n",
    "    # Test basic MPS and MPO operations\n",
    "    mps, mpo = test_mps_mpo_operations()\n",
    "    \n",
    "    # Test two-qubit gate application\n",
    "    bell_state = test_two_qubit_gate()\n",
    "    \n",
    "    print(\"\\nAll tests completed successfully!\")\n",
    "    return mps, mpo, bell_state\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72016a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
